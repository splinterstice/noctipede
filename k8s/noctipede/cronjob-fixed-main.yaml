apiVersion: batch/v1
kind: CronJob
metadata:
  name: noctipede-crawler-nfs
  namespace: noctipede
  labels:
    app: noctipede-crawler
spec:
  schedule: "*/30 * * * *"  # Every 30 minutes
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      backoffLimit: 2
      activeDeadlineSeconds: 3600  # 1 hour timeout
      template:
        metadata:
          labels:
            app: noctipede-crawler
        spec:
          restartPolicy: Never
          initContainers:
          - name: wait-for-services
            image: busybox:1.35
            command: ["sh", "-c"]
            args:
            - |
              echo "‚è≥ Waiting for required services..."
              
              until nc -z tor-proxy 9150; do
                echo "‚è≥ Tor proxy not ready, waiting..."
                sleep 5
              done
              echo "‚úÖ Tor proxy is ready!"
              
              until nc -z i2p-proxy 4444; do
                echo "‚è≥ I2P proxy not ready, waiting..."
                sleep 5
              done
              echo "‚úÖ I2P proxy is ready!"
              
              until nc -z noctipede-portal-service 8080; do
                echo "‚è≥ Portal service not ready, waiting..."
                sleep 5
              done
              echo "‚úÖ Portal service is ready!"
          - name: verify-sites-file
            image: busybox:1.35
            command: ["sh", "-c"]
            args:
            - |
              echo "üìã Verifying sites.txt file from NFS..."
              if [ -f /nfs-sites/sites.txt ]; then
                echo "‚úÖ Found sites.txt with $(wc -l < /nfs-sites/sites.txt) sites"
                echo "üìÑ First 5 sites:"
                head -5 /nfs-sites/sites.txt
              else
                echo "‚ùå sites.txt not found in NFS mount!"
                echo "üìÅ NFS directory contents:"
                ls -la /nfs-sites/
                exit 1
              fi
            volumeMounts:
            - name: nfs-sites
              mountPath: /nfs-sites
          containers:
          - name: noctipede-crawler
            image: ghcr.io/splinterstice/noctipede:latest
            imagePullPolicy: Always
            command: ["sh", "-c"]
            args:
            - |
              echo "üöÄ Starting Noctipede Crawler with NFS sites..."
              echo "üìã Using sites file: $SITES_FILE_PATH"
              echo "üìä Total sites to crawl: $(wc -l < $SITES_FILE_PATH)"
              
              # Wait for system readiness with comprehensive checks
              echo "üîç Checking comprehensive system readiness..."
              while true; do
                READINESS_RESPONSE=$(curl -s http://noctipede-portal-service:8080/api/readiness)
                if echo "$READINESS_RESPONSE" | grep -q '"ready_for_crawling":true'; then
                  break
                fi
                echo "‚è≥ System not ready for crawling, waiting..."
                curl -s http://noctipede-portal-service:8080/api/readiness | grep -o '"readiness_summary":"[^"]*"' || echo "Unable to get readiness status"
                sleep 30
              done
              echo "‚úÖ System is ready for crawling!"
              
              # Start crawler with correct main entry point
              PYTHONPATH=/app python -m crawlers.main
            env:
            - name: SITES_FILE_PATH
              value: "/nfs-sites/sites.txt"
            - name: LOG_LEVEL
              value: "INFO"
            - name: OLLAMA_KEEP_ALIVE
              value: "30s"
            - name: OLLAMA_CONCURRENT_REQUESTS
              value: "3"
            envFrom:
            - configMapRef:
                name: noctipede-config
            - secretRef:
                name: noctipede-secrets
            volumeMounts:
            - name: nfs-sites
              mountPath: /nfs-sites
            - name: output-data
              mountPath: /app/output
            - name: log-data
              mountPath: /app/logs
            resources:
              requests:
                memory: "512Mi"
                cpu: "250m"
              limits:
                memory: "2Gi"
                cpu: "1000m"
          volumes:
          - name: nfs-sites
            persistentVolumeClaim:
              claimName: noctipede-sites-pvc
          - name: output-data
            persistentVolumeClaim:
              claimName: noctipede-output-pvc
          - name: log-data
            persistentVolumeClaim:
              claimName: noctipede-logs-pvc
